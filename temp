Gotcha ‚Äì that actually makes things easier üëç
You already compute a **size-based wait** in `PackageAndUploadFilesTasklet`, so we can:

* keep that logic (your ‚Äú6 seconds + per-MB wait‚Äù), **but**
* instead of doing `Thread.sleep()` blindly in the tasklet, pass that **max wait duration** into the CFT client and use it as a **timeout for polling `/transfers/{idtu}`**.

So the flow becomes:

1. Tasklet zips, encrypts, uploads to COS.
2. Tasklet calls `cftApiClient.notifyAndWait(outPath, encryptedFileName, maxWait)`.
3. `notifyAndWait`:

   * POSTs (exactly like your current `notifyUpload`),
   * reads `idtu` from the POST response,
   * polls `GET /transfers/{idtu}` until:

     * `sentinel = COMPLETED && diagi == 0` ‚Üí ‚úÖ return;
     * `sentinel = SENDING` and still within `maxWait` ‚Üí ‚è≥ sleep a bit and retry;
     * `sentinel = CANCELLED` or `diagi != 0` or timeout ‚Üí ‚ùå log `diagi` + `diagnostic` and throw ‚Üí step fails ‚Üí job will be retried by scheduler.

Below is how you can wire this in **step-by-step**.

---

## 1Ô∏è‚É£ Change in `PackageAndUploadFilesTasklet`

At the bottom of your method (roughly this area from the screenshot):

```java
// Step 5: Call CFT API
log.info("CFT notify enabled : {}", cftEnabled);
if (cftEnabled) {
    cftApiClient.notifyUpload(key, encryptedFileName);

    // SIZE-BASED GRACE before moving to processed ---
    long bytes = encryptedFile.length();
    Duration grace = pickWaitByTier(bytes, waittime);
    log.info("Payload size = {} bytes ({}). Grace wait before move = {}",
             bytes, human(bytes), grace);
    if (!grace.isZero()) {
        try {
            Thread.sleep(grace.toMillis());
        } catch (InterruptedException ie) {
            Thread.currentThread().interrupt();
        }
    }
}

addProcessedKey(stepExecution, encryptedFileName);
if (moveEnabled) {
    moveToProcessed(encryptedFileName, key);
}
```

Replace the **notify+sleep block** with a single call that passes your computed wait to the client:

```java
// Step 5: Call CFT API + wait for transfer completion
log.info("CFT notify enabled : {}", cftEnabled);
if (cftEnabled) {
    long bytes = encryptedFile.length();
    Duration maxWait = pickWaitByTier(bytes, waittime);
    log.info("Payload size = {} bytes ({}). Max wait window for CFT = {}",
             bytes, human(bytes), maxWait);

    cftApiClient.notifyAndWaitForCompletion(key, encryptedFileName, maxWait);
}

addProcessedKey(stepExecution, encryptedFileName);
if (moveEnabled) {
    moveToProcessed(encryptedFileName, key);
}
```

So the tasklet no longer sleeps itself; it delegates that to the CFT client, which will actively **check sentinel + diagi** instead of guessing.

---

## 2Ô∏è‚É£ Update `CftApiClient` ‚Äì POST + GET with polling

You already have `notifyUpload(String outPath, String fileName)`. We‚Äôll refactor that into a new method:

```java
public void notifyAndWaitForCompletion(String outPath, String fileName, Duration maxWait) {
    try {
        log.info("CFT notify started");

        String apiUrl = baseURL + "?part={part}&idtf={idtf}"; // your existing URL
        HttpHeaders headers = new HttpHeaders();
        headers.setContentType(MediaType.APPLICATION_JSON);

        Map<String, String> requestBody = new HashMap<>();
        requestBody.put("fname", outPath);
        requestBody.put("pname", fileName);
        requestBody.put("sync", "YES");

        String jsonPayload = objectMapper.writeValueAsString(requestBody);
        HttpEntity<String> requestEntity = new HttpEntity<>(jsonPayload, headers);

        Map<String, String> uriVariables = new HashMap<>();
        uriVariables.put("part", destPART);
        uriVariables.put("idtf", destIDF);

        log.info("Sending POST request to: {}", apiUrl);
        log.info("Headers: {}", headers);
        log.info("Body: {}", requestBody);

        ResponseEntity<String> response =
                restTemplate.exchange(apiUrl, HttpMethod.POST, requestEntity,
                                      String.class, uriVariables);

        log.info("CFT POST Response status: {}", response.getStatusCode());
        log.info("CFT POST Response body: {}", response.getBody());

        // --- extract idtu from POST response ---
        String body = response.getBody();
        JsonNode root = objectMapper.readTree(body);
        String idtu = root.path("idtu").asText(null);   // adjust field name if needed

        if (idtu == null || idtu.isEmpty()) {
            throw new IllegalStateException("CFT POST response did not contain idtu");
        }

        // --- poll GET /transfers/{idtu} until done or timeout ---
        waitUntilTransferFinished(idtu, maxWait);

        log.info("CFT notify + transfer status checks completed successfully for idtu={}", idtu);

    } catch (Exception e) {
        log.error("Error during CFT notifyAndWaitForCompletion", e);
        throw new IllegalStateException("CFT notify failed", e);
    }
}
```

### Status DTO (for GET)

```java
public class TransferStatusResponse {
    private String idtu;
    private String sentinel;   // "COMPLETED", "SENDING", "CANCELLED"
    private int diagi;
    private String diagnostic;

    // getters and setters
}
```

### GET `/transfers/{idtu}` + polling using `maxWait`

```java
private TransferStatusResponse getTransferStatus(String idtu) {
    String url = baseURL + "/transfers/{idtu}";   // adjust if needed

    Map<String, String> uriVariables = new HashMap<>();
    uriVariables.put("idtu", idtu);

    ResponseEntity<String> response =
            restTemplate.exchange(url, HttpMethod.GET, null, String.class, uriVariables);

    log.info("CFT GET status for idtu={} -> {}", idtu, response.getStatusCode());
    log.debug("CFT GET body: {}", response.getBody());

    try {
        return objectMapper.readValue(response.getBody(), TransferStatusResponse.class);
    } catch (Exception e) {
        throw new IllegalStateException("Failed to parse CFT status for idtu=" + idtu, e);
    }
}

private void waitUntilTransferFinished(String idtu, Duration maxWait) {
    // you can tweak these
    Duration pollInterval = Duration.ofSeconds(5);
    Instant deadline = Instant.now().plus(maxWait);

    while (true) {
        TransferStatusResponse status = getTransferStatus(idtu);

        String sentinel = status.getSentinel();
        int diagi = status.getDiagi();
        String diagText = status.getDiagnostic();

        log.info("CFT status idtu={} sentinel={} diagi={} diagnostic={}",
                 idtu, sentinel, diagi, diagText);

        if ("COMPLETED".equalsIgnoreCase(sentinel) && diagi == 0) {
            // ‚úÖ good
            return;
        }

        if ("CANCELLED".equalsIgnoreCase(sentinel) || diagi != 0) {
            // ‚ùå cancelled or error ‚Äì fail the batch
            throw new IllegalStateException(
                    String.format("CFT transfer FAILED for idtu=%s, sentinel=%s, diagi=%d, diagnostic=%s",
                                  idtu, sentinel, diagi, diagText));
        }

        if ("SENDING".equalsIgnoreCase(sentinel)) {
            if (Instant.now().isAfter(deadline)) {
                // ‚ùå still SENDING after our size-based wait window
                throw new IllegalStateException(
                        String.format("CFT transfer still SENDING after %s for idtu=%s; diagi=%d diagnostic=%s",
                                      maxWait, idtu, diagi, diagText));
            }

            try {
                Thread.sleep(pollInterval.toMillis());
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
                throw new IllegalStateException("Interrupted while waiting for CFT status", e);
            }
        } else {
            // any unexpected sentinel
            throw new IllegalStateException(
                    String.format("Unexpected CFT sentinel='%s' for idtu=%s, diagi=%d, diagnostic=%s",
                                  sentinel, idtu, diagi, diagText));
        }
    }
}
```

---

### What this gives you, with your existing wait logic

* You **still use your size-based wait** (`pickWaitByTier`) ‚Äî but now as a **maximum time window** for CFT to finish.
* Instead of ‚Äúblind sleep for X seconds‚Äù, you now **actively ask CFT**:

  * `sentinel = COMPLETED && diagi = 0` ‚Üí OK ‚Üí batch continues exactly like before.
  * `sentinel = SENDING`:

    * keep polling while total time ‚â§ your size-based wait;
    * if still `SENDING` after that ‚Üí throw ‚Üí job fails ‚Üí scheduler can retry.
  * `sentinel = CANCELLED` or `diagi != 0`:

    * log `diagi` and `diagnostic`,
    * throw ‚Üí job fails (and files are kept / moved to `/failed` according to your listener).

You don‚Äôt need to change the rest of your pipeline (cleanup listener, COS tracking, etc.); just replace the old `Thread.sleep` with this smarter `notifyAndWaitForCompletion`.

If you want, you can paste a sample JSON of the `/transfers/{idtu}` response and I‚Äôll adjust the `TransferStatusResponse` fields exactly to match it.



Perfect, then let‚Äôs wire it exactly like this:

* You **keep the files in `incoming/` & `outgoing/` during the job** (other API can read them).
* You already have a **wait time based on file size**, so by the time the job ends, the API *should* have had time to transfer.
* In the **cleanup listener**:

  * On **SUCCESS** ‚Üí delete tracked input/output files.
  * On **FAILURE** ‚Üí move them to `/failed/...` and never delete.

Here‚Äôs a clean implementation + JUnit for **both success and fail scenarios**.

---

## 1Ô∏è‚É£ Context helper ‚Äì track files to clean up

```java
package com.yourcompany.batch.cos;

import org.springframework.batch.core.JobExecution;
import org.springframework.batch.core.StepExecution;
import org.springframework.batch.item.ExecutionContext;

import java.util.ArrayList;
import java.util.Collections;
import java.util.List;

public interface CosCleanupContextSupport {

    String FILES_TO_DELETE_ON_SUCCESS = "filesToDeleteOnSuccess";

    @SuppressWarnings("unchecked")
    default void addFileToDeleteOnSuccess(StepExecution stepExecution, String key) {
        JobExecution jobExecution = stepExecution.getJobExecution();
        ExecutionContext jobContext = jobExecution.getExecutionContext();

        List<String> keys = (List<String>) jobContext.get(FILES_TO_DELETE_ON_SUCCESS);
        if (keys == null) {
            keys = new ArrayList<>();
        }

        keys.add(key);
        // IMPORTANT: re-put list so Spring Batch marks EC as dirty
        jobContext.put(FILES_TO_DELETE_ON_SUCCESS, keys);
    }

    @SuppressWarnings("unchecked")
    default List<String> getFilesToDeleteOnSuccess(JobExecution jobExecution) {
        ExecutionContext jobContext = jobExecution.getExecutionContext();
        List<String> keys = (List<String>) jobContext.get(FILES_TO_DELETE_ON_SUCCESS);
        return keys == null ? Collections.emptyList() : keys;
    }
}
```

üëâ **Contract:** you store the **real COS keys** you used, e.g.:

* `incoming/file1.csv.zip.pgp`
* `outgoing/invoices_001.xml.zip.pgp`

No `/processed`, no leading `/`.

---

## 2Ô∏è‚É£ Listener ‚Äì delete on success, move to `/failed` on failure

```java
package com.yourcompany.batch.cos;

import org.springframework.batch.core.BatchStatus;
import org.springframework.batch.core.JobExecution;
import org.springframework.batch.core.JobExecutionListener;
import org.springframework.stereotype.Component;

import java.util.List;

@Component
public class CosCleanupListener implements JobExecutionListener, CosCleanupContextSupport {

    private final CosService cosService;

    public CosCleanupListener(CosService cosService) {
        this.cosService = cosService;
    }

    @Override
    public void beforeJob(JobExecution jobExecution) {
        // nothing
    }

    @Override
    public void afterJob(JobExecution jobExecution) {
        List<String> keys = getFilesToDeleteOnSuccess(jobExecution);
        if (keys.isEmpty()) {
            // No input/output files tracked (e.g. no-file day)
            return;
        }

        BatchStatus status = jobExecution.getStatus();

        if (status == BatchStatus.COMPLETED) {
            // ‚úÖ SUCCESS ‚Üí delete from incoming/outgoing
            keys.forEach(cosService::deleteFile);

        } else if (status == BatchStatus.FAILED
                || status == BatchStatus.STOPPED
                || status == BatchStatus.ABANDONED) {
            // ‚ùå FAIL/STOPPED ‚Üí archive under /failed and keep
            keys.forEach(cosService::moveToFailed);
        }
        // For STARTING/STARTED etc, do nothing.
    }
}
```

And your `CosService` roughly like:

```java
public class CosService {

    private final AmazonS3 s3Client;
    private final String bucketName;

    public CosService(AmazonS3 s3Client, String bucketName) {
        this.s3Client = s3Client;
        this.bucketName = bucketName;
    }

    public void deleteFile(String key) {
        if (!s3Client.doesObjectExist(bucketName, key)) {
            return; // or log and return
        }
        s3Client.deleteObject(bucketName, key);
    }

    public String moveToFailed(String key) {
        // incoming/file1.csv.zip.pgp ‚Üí failed/incoming/file1.csv.zip.pgp
        String failedKey = "failed/" + key;

        CopyObjectRequest copyReq =
                new CopyObjectRequest(bucketName, key, bucketName, failedKey);
        s3Client.copyObject(copyReq);
        s3Client.deleteObject(bucketName, key);

        return failedKey;
    }
}
```

---

## 3Ô∏è‚É£ JUnit ‚Äì success & fail scenarios

### Test class for listener

```java
package com.yourcompany.batch.cos;

import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.mockito.Mockito;
import org.springframework.batch.core.BatchStatus;
import org.springframework.batch.core.JobExecution;
import org.springframework.batch.core.StepExecution;

import static org.mockito.ArgumentMatchers.anyString;
import static org.mockito.Mockito.*;

class CosCleanupListenerTest {

    private CosService cosService;
    private CosCleanupListener listener;
    private CosCleanupContextSupport contextSupport;

    @BeforeEach
    void setUp() {
        this.cosService = Mockito.mock(CosService.class);
        this.listener = new CosCleanupListener(cosService);
        this.contextSupport = listener; // listener implements the interface
    }

    @Test
    void afterJob_completed_shouldDeleteTrackedFiles() {
        // given
        JobExecution jobExecution = new JobExecution(1L);
        StepExecution stepExecution = new StepExecution("step1", jobExecution);

        // Track original keys (incoming + outgoing)
        contextSupport.addFileToDeleteOnSuccess(stepExecution, "incoming/file1.csv.zip.pgp");
        contextSupport.addFileToDeleteOnSuccess(stepExecution, "outgoing/invoices_001.xml.zip.pgp");

        jobExecution.setStatus(BatchStatus.COMPLETED);

        // when
        listener.afterJob(jobExecution);

        // then
        verify(cosService).deleteFile("incoming/file1.csv.zip.pgp");
        verify(cosService).deleteFile("outgoing/invoices_001.xml.zip.pgp");
        verify(cosService, never()).moveToFailed(anyString());
        verifyNoMoreInteractions(cosService);
    }

    @Test
    void afterJob_failed_shouldMoveTrackedFilesToFailed() {
        // given
        JobExecution jobExecution = new JobExecution(2L);
        StepExecution stepExecution = new StepExecution("step1", jobExecution);

        contextSupport.addFileToDeleteOnSuccess(stepExecution, "incoming/file1.csv.zip.pgp");
        contextSupport.addFileToDeleteOnSuccess(stepExecution, "outgoing/invoices_001.xml.zip.pgp");

        jobExecution.setStatus(BatchStatus.FAILED);

        // when
        listener.afterJob(jobExecution);

        // then
        verify(cosService).moveToFailed("incoming/file1.csv.zip.pgp");
        verify(cosService).moveToFailed("outgoing/invoices_001.xml.zip.pgp");
        verify(cosService, never()).deleteFile(anyString());
        verifyNoMoreInteractions(cosService);
    }

    @Test
    void afterJob_completedAndNoTrackedFiles_shouldDoNothing() {
        // given
        JobExecution jobExecution = new JobExecution(3L);
        jobExecution.setStatus(BatchStatus.COMPLETED);

        // when
        listener.afterJob(jobExecution);

        // then
        verifyNoInteractions(cosService);
    }

    @Test
    void afterJob_startedStatus_shouldDoNothingEvenIfKeysExist() {
        // given
        JobExecution jobExecution = new JobExecution(4L);
        StepExecution stepExecution = new StepExecution("step1", jobExecution);

        contextSupport.addFileToDeleteOnSuccess(stepExecution, "incoming/file1.csv.zip.pgp");
        jobExecution.setStatus(BatchStatus.STARTED);

        // when
        listener.afterJob(jobExecution);

        // then
        verifyNoInteractions(cosService);
    }
}
```

This covers your **success** and **fail** scenarios exactly:

* ‚úÖ `COMPLETED` ‚Üí `deleteFile(...)` called for each tracked key.
* ‚úÖ `FAILED` ‚Üí `moveToFailed(...)` called for each tracked key.
* üîá No keys ‚Üí no COS calls.
* üîá Non-final status (e.g. STARTED) ‚Üí no cleanup.

---

Given you already have the **size-based wait time**, this approach is a good first attempt:

* Other API has time to read from `incoming/` / `outgoing/`.
* Once your batch finishes:

  * If all good ‚Üí those files are cleaned.
  * If something broke ‚Üí they are preserved under `/failed/...` forever.

If you later notice even the wait isn‚Äôt always enough, you can still switch to a **delayed cleanup job** without changing how you track keys.
